{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307f9766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "\n",
    "def sbert_embed(text):\n",
    "    model = SentenceTransformer('paraphrase-albert-small-v2')\n",
    "    return model.encode(text)\n",
    "\n",
    "def openai_embed(text):\n",
    "    client = OpenAI()\n",
    "    response = client.embeddings.create(input=text, model=\"text-embedding-ada-002\")\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4685908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def chunk_text(text, max_tokens=500):\n",
    "    \"\"\"Splits long text into chunks of approximately max_tokens (words â‰ˆ tokens).\"\"\"\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), max_tokens):\n",
    "        yield ' '.join(words[i:i + max_tokens])\n",
    "\n",
    "def load_pdfs_from_folder(folder_path):\n",
    "    pdf_texts = []\n",
    "    pdf_paths = Path(folder_path).glob(\"*.pdf\") \n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        reader = PdfReader(str(pdf_path))\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() or \"\"  # sometimes pages have no text\n",
    "        pdf_texts.append((str(pdf_path), text))\n",
    "    \n",
    "    return pdf_texts # returns tuples, filename, full_text\n",
    "\n",
    "\n",
    "def create_embedding(embedding_model):\n",
    "    pdfs = load_pdfs_from_folder(\"./data/v1/docs\") # 1. Load PDFs\n",
    "    embedded_pdfs = []\n",
    "    \n",
    "    if (embedding_model==\"sbert\"):\n",
    "        for filename, text in pdfs:\n",
    "            for chunk in chunk_text(text, max_tokens=500):\n",
    "                embedding = sbert_embed(chunk)\n",
    "                embedded_pdfs.append((filename, embedding, chunk))\n",
    "    \n",
    "    elif (embedding_model==\"open_ai\"):\n",
    "        for filename, text in pdfs:\n",
    "            for chunk in chunk_text(text, max_tokens=500):\n",
    "                embedding = openai_embed(chunk)\n",
    "                embedded_pdfs.append((filename, embedding, chunk))\n",
    "\n",
    "    else:\n",
    "        print(f\"embedding model {embedding_model} is not in this testing code\")\n",
    "\n",
    "    return embedded_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46436a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_embeddings = create_embedding(\"sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89711144",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_embeddings = create_embedding(\"open_ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5776002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "\n",
    "client = QdrantClient(\"localhost\", port=6333)\n",
    "SBERT_EMBED_SIZE = 768\n",
    "OPENAI_EMBED_SIZE = 1536\n",
    "\n",
    "# Create a collection for each embedding type\n",
    "for embed_type in [{'name': \"sbert_embedding_new\", 'size': SBERT_EMBED_SIZE, 'embeddings': sbert_embeddings}, \n",
    "                   {'name': \"openai_embedding_new\", 'size': OPENAI_EMBED_SIZE, 'embeddings': openai_embeddings}]:\n",
    "    client.create_collection(\n",
    "        collection_name=f\"{embed_type['name']}_collection\",\n",
    "        vectors_config=VectorParams(size=embed_type['size'], distance=Distance.COSINE)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4382287",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=f\"sbert_embedding_new_collection\",\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": original_text}\n",
    "        )\n",
    "        for idx, (_, embedding, original_text) in enumerate(embed_type['embeddings'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b18628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=f\"openai_embedding_new_collection\",\n",
    "    points=[\n",
    "        PointStruct(\n",
    "            id=idx,\n",
    "            vector=embedding,\n",
    "            payload={\"text\": original_text}\n",
    "        )\n",
    "        for idx, (_, embedding, original_text) in enumerate(embed_type['embeddings'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "44fb05ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def openai_generate(prompt):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=300,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b94305a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rag(query, embed_fn, collection_name, llm_fn, top_k=5):\n",
    "    from qdrant_client import QdrantClient\n",
    "\n",
    "    # Connect to Qdrant\n",
    "    client = QdrantClient(host=\"localhost\", port=6333)\n",
    "    \n",
    "    # Embed query\n",
    "    query_vec = embed_fn(query)\n",
    "\n",
    "    # Search Qdrant\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_vec,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    # Extract top-k text chunks\n",
    "    chunks = [hit.payload['text'] for hit in search_result]\n",
    "    context = \"\\n\\n\".join(chunks)\n",
    "\n",
    "    # Create prompt for LLM\n",
    "    prompt = f\"Use the context to answer:\\n\\n{context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "\n",
    "    # Generate answer using LLM\n",
    "    return llm_fn(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "442ae1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4124/100553390.py:5: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.9.2. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(host=\"localhost\", port=6333)\n",
      "/tmp/ipykernel_4124/100553390.py:11: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    }
   ],
   "source": [
    "query = \"How did the economy perform in 2015?\"\n",
    "\n",
    "sbert_answer = simple_rag(query, sbert_embed, \"sbert_embedding_new_collection\", openai_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "542de84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The economy performed well in 2015, with a net income of $125 million in the revolving fund.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbert_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bd9e5001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4124/100553390.py:5: UserWarning: Qdrant client version 1.14.2 is incompatible with server version 1.9.2. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  client = QdrantClient(host=\"localhost\", port=6333)\n",
      "/tmp/ipykernel_4124/100553390.py:11: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    'How did the economy perform in 2016?',\n",
    "    'What economic sectors did well in 2015?',\n",
    "    'What were some economic goals of 2016?',\n",
    "    'What were some of the challenges of the year 2022?',\n",
    "    'How did education change in the year 2022?'\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for query in queries:\n",
    "    sbert_answer = simple_rag(query, sbert_embed, \"sbert_embedding_new_collection\", openai_generate)\n",
    "    openai_answer = simple_rag(query, sbert_embed, \"openai_embedding_new_collection\", openai_generate)\n",
    "    results.append({'query': query, 'sbert_answer': sbert_answer, 'openai_answer': openai_answer})\n",
    "\n",
    "f = open('result.md', 'w')\n",
    "for res in results:\n",
    "    f.write(f'* {res[\"query\"]}\\n')\n",
    "    f.write(f'\\t* SBERT: {res[\"sbert_answer\"]}\\n')\n",
    "    f.write(f'\\t* OPENAI: {res[\"openai_answer\"]}\\n')\n",
    "    f.write('\\n')\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1faaf",
   "metadata": {},
   "source": [
    "# Results:\n",
    "* How did the economy perform in 2016?\n",
    "\t* SBERT: Based on the information provided, the economy performed well in 2016 in terms of the revolving fund net income. The target for FY 2016 was met, with a net income of $162,463,231, showing an improvement from the previous year. Additionally, progress was made in refining cost accounting models and improving data reliability, indicating positive developments in financial management.\n",
    "\t* OPENAI: Based on the information provided, the economy performed well in 2016. The revolving fund net income increased to $162,463,231, which exceeded the target of â‰¥$0. Additionally, progress was made in refining cost accounting models, improving data reliability, and streamlining activities related to labor costs allocation. Overall, the economy showed positive growth and progress in various areas related to cost accounting and financial management.\n",
    "\n",
    "* What economic sectors did well in 2015?\n",
    "\t* SBERT: Based on the provided information, it is not explicitly stated which economic sectors did well in 2015. The data primarily focuses on performance measures related to IT systems, employee engagement, and other specific initiatives within the Federal government.\n",
    "\t* OPENAI: Based on the provided information, it is not explicitly stated which economic sectors did well in 2015. The data primarily focuses on performance measures related to IT systems, employee engagement, and retirement benefits within the Federal government.\n",
    "\n",
    "* What were some economic goals of 2016?\n",
    "\t* SBERT: Some economic goals of 2016 included improving the ability of the Federal human resource workforce to attract, develop, train, and support talent in the Federal Government by developing and launching a Federal HR curriculum, and transforming hiring, pay, and benefits across the Federal Government to attract and retain the best civilian workforce.\n",
    "\t* OPENAI: Some economic goals of 2016 included improving the ability of the Federal human resource workforce to attract, develop, train, and support talent in the Federal Government, building and launching curricula for employee relations and labor relations, and reducing the complexity and costs to administer Federal employee retirement earned benefits.\n",
    "\n",
    "* What were some of the challenges of the year 2022?\n",
    "\t* SBERT: Some of the challenges of the year 2022 included low compliance with Government-wide past performance reporting requirements in contracting actions, insufficient resources for OPM managers and staff to get their jobs done, and the need to establish a sustainable funding and staffing model for OPM to better meet its mission.\n",
    "\t* OPENAI: Some of the challenges of the year 2022 included low compliance with Government-wide past performance reporting requirements in contracting actions and the need to establish a sustainable funding and staffing model for OPM to better meet its mission. Additionally, there were issues with OPM managers and staff indicating they did not have sufficient resources to get their jobs done.\n",
    "\n",
    "* How did education change in the year 2022?\n",
    "\t* SBERT: In 2022, education underwent significant changes due to the COVID-19 pandemic. Schools had to quickly pivot to virtual learning, leading to the Department of Education providing support to millions of children, families, and educators. The focus was on transitioning back to in-person learning, assessing students' learning needs, and providing evidence-based resources and support. Additionally, there were new investments in postsecondary education through various relief funds to ensure learning continuity during the pandemic. Overall, the education system adapted to the challenges brought on by the pandemic and worked towards improving outcomes for all students.\n",
    "\t* OPENAI: In 2022, education underwent significant changes due to the COVID-19 pandemic. The Department of Education had to rapidly pivot to provide support for virtual learning as schools transitioned to online education. The Department focused on providing evidence-based strategies and practices to support students, families, and educators during this challenging time. Additionally, there was increased funding and support for postsecondary education through various relief funds to ensure learning continued for students during the pandemic. Overall, the education system adapted to new challenges and focused on providing equitable opportunities and outcomes for all students.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c13001",
   "metadata": {},
   "source": [
    "# My Comparison:\n",
    "\n",
    "Overall the responses are very similar and only differ in some word and sentence structure choices. When reading the responses side by side, there are many similarities in word choices as well as flow of the overall report. It was interesting to compare these models and see how they slightly differ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "krag_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
